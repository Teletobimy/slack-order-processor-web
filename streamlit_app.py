# -*- coding: utf-8 -*-
"""
Slack ì¶œê³  ë°ì´í„° ì²˜ë¦¬ ìë™í™” - Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime, timedelta
import tempfile
import zipfile
from io import BytesIO

# ë¡œì»¬ ëª¨ë“ˆ import
from slack_fetcher import SlackFetcher
from aggregator import DataAggregator
from excel_generator import ExcelGenerator

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Slack ì¶œê³  ë°ì´í„° ì²˜ë¦¬",
    page_icon="ğŸ“¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
def setup_console_encoding():
    """ì½˜ì†” ì¸ì½”ë”© ì„¤ì •"""
    try:
        if os.name == 'nt':  # Windows
            os.system('chcp 65001 > nul')
        return True
    except:
        return False

# ì„¤ì • ë¡œë“œ
@st.cache_data
def load_config():
    """ì„¤ì • ë¡œë“œ (í™˜ê²½ ë³€ìˆ˜ë§Œ ì‚¬ìš©)"""
    try:
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        config = {
            "slack_bot_token": os.getenv("SLACK_BOT_TOKEN"),
            "channel_id": os.getenv("CHANNEL_ID"),
            "openai_api_key": os.getenv("OPENAI_API_KEY"),
            "warehouse_code": os.getenv("WAREHOUSE_CODE", "100")
        }
        
        # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        required_vars = ["slack_bot_token", "channel_id", "openai_api_key"]
        missing_vars = [var for var in required_vars if not config.get(var)]
        
        if missing_vars:
            st.error(f"ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
            st.info("Streamlit Cloudì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return None
        
        return config
    except Exception as e:
        st.error(f"ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

# ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
@st.cache_data
def load_products_db():
    """ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
    try:
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists("products_map.json"):
            st.error("products_map.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with st.expander("ğŸ” íŒŒì¼ ëª©ë¡ í™•ì¸", expanded=False):
                st.info("í˜„ì¬ ë””ë ‰í† ë¦¬ íŒŒì¼ë“¤:")
                for file in os.listdir("."):
                    st.write(f"- {file}")
            return None
            
        with open("products_map.json", 'r', encoding='utf-8') as f:
            products_db = json.load(f)
            st.success(f"ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì„±ê³µ: {len(products_db)}ê°œ ë¸Œëœë“œ")
            return products_db
    except Exception as e:
        st.error(f"ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´", expanded=False):
            import traceback
            st.code(traceback.format_exc())
        return None

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.title("ğŸ“¦ Slack ì¶œê³  ë°ì´í„° ì²˜ë¦¬ ìë™í™”")
    st.markdown("---")
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    if not config:
        st.error("í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.markdown("""
        ### ğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë°©ë²•
        
        Streamlit Cloudì—ì„œ ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:
        
        1. **SLACK_BOT_TOKEN**: Slack Bot Token (xoxb-ë¡œ ì‹œì‘)
        2. **OPENAI_API_KEY**: OpenAI API Key (sk-ë¡œ ì‹œì‘)  
        3. **CHANNEL_ID**: Slack ì±„ë„ ID (Cë¡œ ì‹œì‘)
        4. **WAREHOUSE_CODE**: ì°½ê³  ì½”ë“œ (ê¸°ë³¸ê°’: 100)
        
        í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í›„ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.
        """)
        return
    
    products_db = load_products_db()
    if not products_db:
        st.error("ì œí’ˆ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ì‚¬ì´ë“œë°” - ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ë‚ ì§œ ì„ íƒ
        st.subheader("ğŸ“… ì²˜ë¦¬ ê¸°ê°„")
        today = datetime.now().date()
        
        # SlackFetcher ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
        if today.weekday() == 0:  # ì›”ìš”ì¼ì´ë©´ ê¸ˆìš”ì¼~ì¼ìš”ì¼
            default_start = today - timedelta(days=3)  # ê¸ˆìš”ì¼
            default_end = today - timedelta(days=1)     # ì¼ìš”ì¼
        else:
            # í‰ì¼ì¸ ê²½ìš° ì§ì „ ë‚ ì§œë§Œ
            default_start = today - timedelta(days=1)   # ì–´ì œ
            default_end = today - timedelta(days=1)     # ì–´ì œ
        
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            value=default_start,
            max_value=today
        )
        
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ", 
            value=default_end,
            max_value=today
        )
        
        if start_date > end_date:
            st.error("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return
        
        # ì±„ë„ ì„ íƒ
        st.subheader("ğŸ“¢ ì±„ë„ ì„¤ì •")
        channel_id = st.text_input(
            "ì±„ë„ ID",
            value=config.get("channel_id", ""),
            help="Slack ì±„ë„ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # ì²˜ë¦¬ ì˜µì…˜
        st.subheader("ğŸ”§ ì²˜ë¦¬ ì˜µì…˜")
        include_threads = st.checkbox("ìŠ¤ë ˆë“œ ëŒ“ê¸€ í¬í•¨", value=True)
        include_files = st.checkbox("ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬", value=True)
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“Š ë°ì´í„° ì²˜ë¦¬")
        
        # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸš€ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘", type="primary"):
            if not channel_id:
                st.error("ì±„ë„ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # 1. Slack ë°ì´í„° ìˆ˜ì§‘
                status_text.text("ğŸ“¡ Slack ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                progress_bar.progress(10)
                
                fetcher = SlackFetcher(config)
                fetcher.channel_id = channel_id
                
                messages = fetcher.fetch_messages(
                    start_date.strftime('%Y-%m-%d'),
                    end_date.strftime('%Y-%m-%d')
                )
                
                if not messages:
                    st.warning("ì„ íƒí•œ ê¸°ê°„ì— ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                st.success(f"âœ… {len(messages)}ê°œ ë©”ì‹œì§€ ìˆ˜ì§‘ ì™„ë£Œ")
                
                # 2. ë©”ì‹œì§€ ì²˜ë¦¬
                status_text.text("ğŸ”„ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘...")
                progress_bar.progress(30)
                
                processed_messages = fetcher.process_messages_with_threads(messages)
                st.success(f"âœ… {len(processed_messages)}ê°œ ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ")
                
                # 3. ë°ì´í„° ì§‘ê³„
                status_text.text("ğŸ“Š ë°ì´í„° ì§‘ê³„ ì¤‘...")
                progress_bar.progress(60)
                
                aggregator = DataAggregator(config)
                aggregated_data = aggregator.aggregate_products(processed_messages)
                
                aggregated_by_brand = aggregated_data.get("aggregated_by_brand", {})
                brands = aggregated_data.get("brands", [])
                
                if not brands:
                    st.warning("ë§¤ì¹­ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ì²˜ë¦¬ëœ ë©”ì‹œì§€ ìˆ˜: " + str(len(processed_messages)))
                    return
                
                st.success(f"âœ… {len(brands)}ê°œ ë¸Œëœë“œì—ì„œ ì œí’ˆ ë§¤ì¹­ ì™„ë£Œ")
                
                # ë””ë²„ê¹… ì •ë³´ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
                with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´ (ê°œë°œììš©)", expanded=False):
                    st.subheader("ì²˜ë¦¬ëœ ë©”ì‹œì§€")
                    for i, msg in enumerate(processed_messages, 1):
                        st.write(f"**ë©”ì‹œì§€ {i}:** {msg.get('text', '')[:100]}...")
                    
                    st.subheader("ì§‘ê³„ëœ ë°ì´í„°")
                    st.json(aggregated_data)
                    
                    st.subheader("ë¸Œëœë“œë³„ ì§‘ê³„")
                    st.json(aggregated_by_brand)
                    
                    st.subheader("ë°œê²¬ëœ ë¸Œëœë“œ")
                    st.write(brands)
                
                # 4. ê²€ì¦ í™”ë©´
                st.markdown("---")
                st.subheader("ğŸ“ ì œí’ˆ ë§¤ì¹­ í™•ì¸")
                
                # ëª¨í˜¸í•œ ì œí’ˆ í‘œì‹œ
                ambiguous_products = aggregated_data.get("ambiguous_products", [])
                if ambiguous_products:
                    st.warning(f"âš ï¸ {len(ambiguous_products)}ê°œ ì œí’ˆì´ ëª¨í˜¸í•©ë‹ˆë‹¤. í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    st.write("**ëª¨í˜¸í•œ ì œí’ˆ ëª©ë¡:**")
                    for i, product in enumerate(ambiguous_products, 1):
                        with st.expander(f"ì œí’ˆ {i}: {product.get('product_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}"):
                            st.write(f"- ìš”ì²­ ì œí’ˆ: {product.get('product_name', '')}")
                            st.write(f"- ìˆ˜ëŸ‰: {product.get('quantity', 0)} {product.get('unit', '')}")
                            st.write(f"- ìš©ëŸ‰: {product.get('capacity', 'ë¯¸ê¸°ì¬')}")
                            st.write(f"- ì‹ ë¢°ë„: {product.get('confidence', 0)}%")
                            
                            # ì‚¬ìš©ì ì„ íƒ
                            key = f"ambiguous_choice_{i}"
                            selected = st.radio(
                                "ì´ ì œí’ˆì´ ë§ìŠµë‹ˆê¹Œ?",
                                options=["ë§¤ì¹­ ìœ ì§€", "ì œì™¸"],
                                key=key,
                                index=0
                            )
                            if selected == "ì œì™¸":
                                # ì œí’ˆ ì œì™¸ ë¡œì§ (ë‚˜ì¤‘ì— êµ¬í˜„)
                                pass
                else:
                    st.success("âœ… ëª¨ë“  ì œí’ˆì´ ëª…í™•í•˜ê²Œ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì •ìƒ ë§¤ì¹­ëœ ì œí’ˆ ìš”ì•½
                st.write("**ë§¤ì¹­ëœ ì œí’ˆ ìš”ì•½:**")
                for brand in brands:
                    with st.expander(f"{brand} ë¸Œëœë“œ ({len(aggregated_by_brand.get(brand, []))}ê°œ ì œí’ˆ)"):
                        for product in aggregated_by_brand.get(brand, []):
                            st.write(f"- {product.get('ì œí’ˆëª…', '')} Ã— {product.get('ì´_ìˆ˜ëŸ‰', 0)}ê°œ")
                
                # ìµœì¢… í™•ì¸ ë²„íŠ¼
                if st.button("âœ… ìµœì¢… í™•ì¸ ë° Excel ìƒì„±", type="primary"):
                    progress_bar.progress(80)
                    status_text.text("ğŸ“„ Excel íŒŒì¼ ìƒì„± ì¤‘...")
                    
                    # 5. Excel ìƒì„±
                    generator = ExcelGenerator(config)
                    
                    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ ìƒì„±
                    with tempfile.TemporaryDirectory() as temp_dir:
                        created_files = generator.create_excel_files_by_brand(aggregated_data, temp_dir)
                        
                        if created_files:
                            progress_bar.progress(100)
                            status_text.text("âœ… ì™„ë£Œ!")
                            
                            # ZIP íŒŒì¼ ìƒì„±
                            zip_buffer = BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                for file_path in created_files:
                                    zip_file.write(file_path, os.path.basename(file_path))
                            zip_buffer.seek(0)
                            
                            st.download_button(
                                label="ğŸ“¥ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ZIP)",
                                data=zip_buffer,
                                file_name=f"ì¶œê³ _ë°ì´í„°_{start_date}_{end_date}.zip",
                                mime="application/zip"
                            )
                            
                            # ë¯¸ë¦¬ë³´ê¸°
                            for file_path in created_files:
                                st.write(f"âœ… {os.path.basename(file_path)} ìƒì„± ì™„ë£Œ")
                        else:
                            st.error("Excel íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    
                    progress_bar.empty()
                    status_text.empty()
                
                return
                
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    with col2:
        st.header("ğŸ“ˆ í†µê³„")
        
        if 'aggregated_data' in locals():
            st.metric("ì´ ì œí’ˆ ì¢…ë¥˜", aggregated_data.get('unique_products', 0))
            st.metric("ì²˜ë¦¬ëœ ìŠ¤ë ˆë“œ", len(aggregated_data.get('thread_summaries', [])))
            st.metric("ë°œê²¬ëœ ë¸Œëœë“œ", len(brands))
        
        st.header("â„¹ï¸ ì •ë³´")
        st.info("""
        **ì²˜ë¦¬ ê³¼ì •:**
        1. Slack ë©”ì‹œì§€ ìˆ˜ì§‘
        2. ì œí’ˆëª… ë° ìˆ˜ëŸ‰ ì¶”ì¶œ
        3. GPTë¥¼ í†µí•œ ì œí’ˆ ë§¤ì¹­
        4. ë¸Œëœë“œë³„ Excel íŒŒì¼ ìƒì„±
        """)
        
        st.header("ğŸ·ï¸ ì§€ì› ë¸Œëœë“œ")
        for brand in products_db.keys():
            st.write(f"â€¢ {brand}")

if __name__ == "__main__":
    setup_console_encoding()
    main()